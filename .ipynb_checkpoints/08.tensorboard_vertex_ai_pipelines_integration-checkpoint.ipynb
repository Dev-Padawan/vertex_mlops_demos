{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eBEO2w9My9py"
   },
   "source": [
    "# Vertex AI TensorBoard integration with Vertex AI Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VL7XCFV7yCBU"
   },
   "source": [
    "## Overview\n",
    "\n",
    "### What is Vertex AI TensorBoard\n",
    "\n",
    "Vertex AI TensorBoard is an enterprise-ready managed version of\n",
    "[Open source TensorBoard](https://www.tensorflow.org/tensorboard/get_started)\n",
    "(TB), which is a Google open source project for machine learning experiment\n",
    "visualization.\n",
    "\n",
    "Vertex AI TensorBoard provides various detailed visualizations, including:\n",
    "\n",
    "*   Tracking and visualizing metrics, such as loss and accuracy over time.\n",
    "*   Visualizing model computational graphs (ops and layers).\n",
    "*   Viewing histograms of weights, biases, or other tensors as they change over time.\n",
    "*   Projecting embeddings to a lower dimensional space.\n",
    "*   Displaying image, text, and audio samples.\n",
    "\n",
    "In addition to powerful visualizations from\n",
    "TensorBoard, Vertex AI TensorBoard provides the following benefits:\n",
    "\n",
    "*  A persistent, shareable link to your experiment's dashboard.\n",
    "\n",
    "*  A searchable list of all experiments in a project.\n",
    "\n",
    "*  Tight integrations with Vertex AI services for model training.\n",
    "\n",
    "*  Enterprise-grade security, privacy, and compliance.\n",
    "\n",
    "With Vertex AI TensorBoard, you can track, visualize, and compare\n",
    "ML experiments and share them with your team.\n",
    "\n",
    "Learn more about [Vertex AI TensorBoard](https://cloud.google.com/vertex-ai/docs/experiments/tensorboard-overview) and [Vertex AI Pipelines](https://cloud.google.com/vertex-ai/docs/pipelines/introduction)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UE8vLw7SlpwE"
   },
   "source": [
    "### Objective\n",
    "\n",
    "This demo shows how to create a training pipeline using the KFP SDK, execute the pipeline in Vertex AI Pipelines, and monitor the training process on Vertex AI TensorBoard in near real time.\n",
    "\n",
    "It uses the following Google Cloud ML services and resources:\n",
    "\n",
    "- Vertex AI Training\n",
    "- Vertex AI TensorBoard\n",
    "- Vertex AI Pipelines\n",
    "\n",
    "The steps performed include:\n",
    "\n",
    "* Setup a service account and Google Cloud Storage buckets.\n",
    "* Construct a KFP pipeline with your custom training code.\n",
    "* Compile and execute the KFP pipeline in Vertex AI Pipelines with Tensorboard enabled for near real time monitoring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fbF2lF8rlp3I"
   },
   "source": [
    "### Dataset\n",
    "\n",
    "Dataset used will be the [flower dataset](https://www.tensorflow.org/datasets/catalog/tf_flowers) provided by TensorFlow. No other datasets are required.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s3moH5AexXpk"
   },
   "source": [
    "## Installation\n",
    "\n",
    "Install the following packages required to execute this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pJwxNvcA8V_c"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "! pip3 install --upgrade --quiet google-cloud-aiplatform \\\n",
    "                                 google-cloud-storage \\\n",
    "                                 \"kfp<2\" \\\n",
    "                                 \"google-cloud-pipeline-components==1.0.20\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "58707a750154"
   },
   "source": [
    "### Colab only: Uncomment the following cell to restart the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f200f10a1da3"
   },
   "outputs": [],
   "source": [
    "# Automatically restart kernel after installs so that your environment can access the new packages\n",
    "# import IPython\n",
    "\n",
    "# app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "oM1iC_MfAts1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ID = \"ibnd-argls-cstmr-demos\"  # @param {type:\"string\"}\n",
    "\n",
    "# Set the project id\n",
    "! gcloud config set project {PROJECT_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "region"
   },
   "source": [
    "#### Set the region\n",
    "\n",
    "**Optional**: Update the 'REGION' variable to specify the region that you want to use. Learn more about [Vertex AI regions](https://cloud.google.com/vertex-ai/docs/general/locations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "nsN5NJKSu-GU"
   },
   "outputs": [],
   "source": [
    "REGION = \"us-central1\"  # @param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z36ycwA4IjYC"
   },
   "source": [
    "#### UUID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MngMavafIrQa"
   },
   "source": [
    "If you're in a live tutorial session, you may be using a shared test account or project.\n",
    "To avoid name collisions between users on resources created, create a  Universal Unique Identifier (uuid)\n",
    "for each instance session. Append the UUID to the name of the resources you create in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "uddA3D7yIn-L"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "\n",
    "# Generate a uuid of a specifed length(default=8)\n",
    "def generate_uuid(length: int = 8) -> str:\n",
    "    return \"\".join(random.choices(string.ascii_lowercase + string.digits, k=length))\n",
    "\n",
    "\n",
    "UUID = generate_uuid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zgPO1eR3CYjk"
   },
   "source": [
    "### Create a Cloud Storage bucket\n",
    "\n",
    "Create a storage bucket to store intermediate artifacts, for example, datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "MzGDU7TWdts_"
   },
   "outputs": [],
   "source": [
    "BUCKET_URI = \"gs://ibnd-argls-ml-demos-storage/08_tensorboard_pipelines\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_bucket"
   },
   "source": [
    "**If your bucket doesn't already exist**: Run the following cell to create your Cloud Storage bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "NIq7R4HZCfIc"
   },
   "outputs": [],
   "source": [
    "# ! gsutil mb -l {REGION} -p {PROJECT_ID} {BUCKET_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hwXxa4Qgnh4Y"
   },
   "source": [
    "## Setup service account and permissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7qXFUiHLoFRw"
   },
   "source": [
    "A service account is used to create custom training job. If you don't want to use your project's Compute Engine service account, set SERVICE_ACCOUNT to another service account ID. You can create a service account by following the [documentation instructions](https://cloud.google.com/iam/docs/creating-managing-service-accounts#creating)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "mpKjfsXumuNV"
   },
   "outputs": [],
   "source": [
    "SERVICE_ACCOUNT = \"998979163436-compute@developer.gserviceaccount.com\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "QbotjwtqKcX4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIS_COLAB = \"google.colab\" in sys.modules\\nif (\\n    SERVICE_ACCOUNT == \"\"\\n    or SERVICE_ACCOUNT is None\\n    or SERVICE_ACCOUNT == \"[your-service-account]\"\\n):\\n    # Get your service account from gcloud\\n    if not IS_COLAB:\\n        shell_output = ! gcloud auth list 2>/dev/null\\n        SERVICE_ACCOUNT = shell_output[2].replace(\"*\", \"\").strip()\\n\\n    else:  # IS_COLAB:\\n        shell_output = ! gcloud projects describe  $PROJECT_ID\\n        project_number = shell_output[-1].split(\":\")[1].strip().replace(\"\\'\", \"\")\\n        SERVICE_ACCOUNT = f\"{project_number}-compute@developer.gserviceaccount.com\"\\n\\n    print(\"Service Account:\", SERVICE_ACCOUNT)\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "'''\n",
    "IS_COLAB = \"google.colab\" in sys.modules\n",
    "if (\n",
    "    SERVICE_ACCOUNT == \"\"\n",
    "    or SERVICE_ACCOUNT is None\n",
    "    or SERVICE_ACCOUNT == \"[your-service-account]\"\n",
    "):\n",
    "    # Get your service account from gcloud\n",
    "    if not IS_COLAB:\n",
    "        shell_output = ! gcloud auth list 2>/dev/null\n",
    "        SERVICE_ACCOUNT = shell_output[2].replace(\"*\", \"\").strip()\n",
    "\n",
    "    else:  # IS_COLAB:\n",
    "        shell_output = ! gcloud projects describe  $PROJECT_ID\n",
    "        project_number = shell_output[-1].split(\":\")[1].strip().replace(\"'\", \"\")\n",
    "        SERVICE_ACCOUNT = f\"{project_number}-compute@developer.gserviceaccount.com\"\n",
    "\n",
    "    print(\"Service Account:\", SERVICE_ACCOUNT)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "UlDhuciOt5vo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mERROR:\u001b[0m (gcloud.projects.add-iam-policy-binding) User [998979163436-compute@developer.gserviceaccount.com] does not have permission to access projects instance [ibnd-argls-cstmr-demos:setIamPolicy] (or it may not exist): Policy update access denied.\n"
     ]
    }
   ],
   "source": [
    "# Grant Cloud Storage permission.\n",
    "'''\n",
    "! gcloud projects add-iam-policy-binding $PROJECT_ID \\\n",
    "    --member=serviceAccount:$SERVICE_ACCOUNT \\\n",
    "    --role=roles/storage.admin \\\n",
    "    --quiet\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "lTKVB71soRyr"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n! gcloud projects add-iam-policy-binding $PROJECT_ID     --member=serviceAccount:$SERVICE_ACCOUNT     --role=roles/aiplatform.user     --quiet\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grant AI Platform permission.\n",
    "'''\n",
    "! gcloud projects add-iam-policy-binding $PROJECT_ID \\\n",
    "    --member=serviceAccount:$SERVICE_ACCOUNT \\\n",
    "    --role=roles/aiplatform.user \\\n",
    "    --quiet\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KIPcg_Xhwvsn"
   },
   "source": [
    "### Import aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "f575a6de11a2"
   },
   "outputs": [],
   "source": [
    "import google.cloud.aiplatform as aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cVmlv9sRbCSs"
   },
   "source": [
    "### Initialize Vertex AI SDK for Python\n",
    "Initialize the Vertex AI SDK for Python for your project and corresponding bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "8db107280f6a"
   },
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HTuoRei4kSiY"
   },
   "source": [
    "#### Vertex AI Pipelines constants\n",
    "\n",
    "Setup up the following constants for Vertex AI Pipelines:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "1ptZBOHFkdk2"
   },
   "outputs": [],
   "source": [
    "PIPELINE_ROOT = \"{}/tensorboard-pipeline-integration/pipeline_root/\".format(BUCKET_URI)\n",
    "BASE_OUTPUT_DIR = \"{}/pipeline-output/tensorboard-pipeline-integration-{}\".format(\n",
    "    BUCKET_URI, UUID\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K2kY3l8zkgvd"
   },
   "source": [
    "Additional imports.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "3z_Z5xhvkmzn"
   },
   "outputs": [],
   "source": [
    "from google_cloud_pipeline_components.v1.custom_job.utils import \\\n",
    "    create_custom_training_job_op_from_component\n",
    "from kfp.v2 import dsl\n",
    "from kfp.v2.dsl import component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IaQjIPvuKLwW"
   },
   "source": [
    "## Create a Vertex AI Tensorboard instance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "svUGBOow_Obj"
   },
   "source": [
    "Create a TensorBoard instance to be used by the Pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "OAe1xJeS_X3F"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Tensorboard\n",
      "Create Tensorboard backing LRO: projects/998979163436/locations/us-central1/tensorboards/9192730846811914240/operations/3942188921508593664\n",
      "Tensorboard created. Resource name: projects/998979163436/locations/us-central1/tensorboards/9192730846811914240\n",
      "To use this Tensorboard in another session:\n",
      "tb = aiplatform.Tensorboard('projects/998979163436/locations/us-central1/tensorboards/9192730846811914240')\n",
      "TensorBoard resource name: projects/998979163436/locations/us-central1/tensorboards/9192730846811914240\n"
     ]
    }
   ],
   "source": [
    "TENSORBOARD_NAME = \"08 - Vertex Pipelines w/ Tensorboard\"  # @param {type:\"string\"}\n",
    "\n",
    "if (\n",
    "    TENSORBOARD_NAME == \"\"\n",
    "    or TENSORBOARD_NAME is None\n",
    "    or TENSORBOARD_NAME == \"[your-tensorboard-name]\"\n",
    "):\n",
    "    TENSORBOARD_NAME = PROJECT_ID + \"-tb-\" + UUID\n",
    "\n",
    "tensorboard = aiplatform.Tensorboard.create(\n",
    "    display_name=TENSORBOARD_NAME, project=PROJECT_ID, location=REGION\n",
    ")\n",
    "TENSORBOARD_RESOURCE_NAME = tensorboard.gca_resource.name\n",
    "print(\"TensorBoard resource name:\", TENSORBOARD_RESOURCE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dR2mOCllvlqN"
   },
   "source": [
    "## Define Python function-based pipeline trainer component\n",
    "In this demo, you define function-based components to train the model.\n",
    "The training code is wrapped as a KFP component that is run in Vertex AI Pipeline.\n",
    "\n",
    "Your training code must be configured to write TensorBoard logs to the Cloud Storage bucket,\n",
    "the location of which the Vertex AI Training service automatically makes available using\n",
    "a predefined environment variable `AIP_TENSORBOARD_LOG_DIR`.\n",
    "\n",
    "This can usually be done by providing `os.environ['AIP_TENSORBOARD_LOG_DIR']`\n",
    "as the log directory to which open source TensorBoard logs are written.\n",
    "\n",
    "For example, in TensorFlow 2.x, you can use following code to create a `tensorboard_callback`:\n",
    "```\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "  log_dir=os.environ['AIP_TENSORBOARD_LOG_DIR'],\n",
    "  histogram_freq=1)\n",
    "```\n",
    "and add the callback to model.fit(...)\n",
    "```\n",
    "# previous things\n",
    "model.compile(...)\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "  log_dir=os.environ['AIP_TENSORBOARD_LOG_DIR'],\n",
    "  histogram_freq=1)\n",
    "  \n",
    "model.fit(dataset, epochs=10, callbacks=[tensorboard_callback])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Ozt73at8mDOb"
   },
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=\"tensorflow/tensorflow:latest\",\n",
    "    packages_to_install=[\"tensorflow_datasets\"],\n",
    ")\n",
    "def trainer(tb_log_dir_env_var: str = \"AIP_TENSORBOARD_LOG_DIR\"):\n",
    "    \"\"\"Training component.\"\"\"\n",
    "    import logging\n",
    "    import os\n",
    "\n",
    "    import tensorflow as tf\n",
    "    import tensorflow_datasets as tfds\n",
    "\n",
    "    IMG_WIDTH = 128\n",
    "\n",
    "    def normalize_img(image):\n",
    "        \"\"\"Normalizes image.\n",
    "\n",
    "        * Resizes image to IMG_WIDTH x IMG_WIDTH pixels\n",
    "        * Casts values from `uint8` to `float32`\n",
    "        * Scales values from [0, 255] to [0, 1]\n",
    "\n",
    "        Returns:\n",
    "          A tensor with shape (IMG_WIDTH, IMG_WIDTH, 3). (3 color channels)\n",
    "        \"\"\"\n",
    "        image = tf.image.resize_with_pad(image, IMG_WIDTH, IMG_WIDTH)\n",
    "        return image / 255.0\n",
    "\n",
    "    def normalize_img_and_label(image, label):\n",
    "        \"\"\"Normalizes image and label.\n",
    "\n",
    "        * Performs normalize_img on image\n",
    "        * Passes through label unchanged\n",
    "\n",
    "        Returns:\n",
    "          Tuple (image, label) where\n",
    "          * image is a tensor with shape (IMG_WIDTH, IMG_WIDTH, 3). (3 color\n",
    "            channels)\n",
    "          * label is an unchanged integer [0, 4] representing flower type\n",
    "        \"\"\"\n",
    "        return normalize_img(image), label\n",
    "\n",
    "    if \"AIP_MODEL_DIR\" not in os.environ:\n",
    "        raise KeyError(\n",
    "            \"The `AIP_MODEL_DIR` environment variable has not been\"\n",
    "            + \"set. See https://cloud.google.com/ai-platform-unified/docs/tutorials/image-recognition-custom/training\"\n",
    "        )\n",
    "    output_directory = os.environ[\"AIP_MODEL_DIR\"]\n",
    "\n",
    "    logging.info(\"Loading and preprocessing data ...\")\n",
    "    dataset = tfds.load(\n",
    "        \"tf_flowers:3.*.*\",\n",
    "        split=\"train\",\n",
    "        try_gcs=True,\n",
    "        shuffle_files=True,\n",
    "        as_supervised=True,\n",
    "    )\n",
    "    dataset = dataset.map(\n",
    "        normalize_img_and_label, num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
    "    )\n",
    "    dataset = dataset.cache()\n",
    "    dataset = dataset.shuffle(1000)\n",
    "    dataset = dataset.batch(128)\n",
    "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    logging.info(\"Creating and training model ...\")\n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Conv2D(\n",
    "                16,\n",
    "                3,\n",
    "                padding=\"same\",\n",
    "                activation=\"relu\",\n",
    "                input_shape=(IMG_WIDTH, IMG_WIDTH, 3),\n",
    "            ),\n",
    "            tf.keras.layers.MaxPooling2D(),\n",
    "            tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\"),\n",
    "            tf.keras.layers.MaxPooling2D(),\n",
    "            tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\"),\n",
    "            tf.keras.layers.MaxPooling2D(),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(512, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(5),  # 5 classes\n",
    "        ]\n",
    "    )\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    # Create a TensorBoard call back and write to the gcs path provided by AIP_TENSORBOARD_LOG_DIR\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=os.environ[tb_log_dir_env_var], histogram_freq=1\n",
    "    )\n",
    "\n",
    "    # Train the model with tensorboard_callback\n",
    "    model.fit(dataset, epochs=14, callbacks=[tensorboard_callback])\n",
    "\n",
    "    logging.info(f\"Exporting SavedModel to: {output_directory}\")\n",
    "    # Add softmax layer for intepretability\n",
    "    probability_model = tf.keras.Sequential([model, tf.keras.layers.Softmax()])\n",
    "    probability_model.save(output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HROisA3gn3lU"
   },
   "source": [
    "### Define a pipeline that uses your component\n",
    "\n",
    "Next, define a pipeline that uses the component that was built in the previous section.\n",
    "\n",
    "The `create_custom_training_job_op_from_component` function converts a given component into a custom training job (`CustomTrainingJobOp`) in Vertex AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "9SD3m-RYoamk"
   },
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    # Default pipeline root. You can override it when submitting the pipeline.\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    "    # A name for the pipeline. Use to determine the pipeline Context.\n",
    "    name=\"tb-pipeline-integration\",\n",
    ")\n",
    "def pipeline():\n",
    "    custom_job_op = create_custom_training_job_op_from_component(\n",
    "        trainer,\n",
    "        tensorboard=TENSORBOARD_RESOURCE_NAME,\n",
    "        base_output_directory=BASE_OUTPUT_DIR,\n",
    "        service_account=SERVICE_ACCOUNT,\n",
    "    )\n",
    "    custom_job_op(project=PROJECT_ID, location=REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9KRh3pHnsbO3"
   },
   "source": [
    "## Compile the pipeline\n",
    "\n",
    "Next, compile the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "oB4DI1E9seRe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/kfp/v2/compiler/compiler.py:1293: FutureWarning: APIs imported from the v1 namespace (e.g. kfp.dsl, kfp.components, etc) will not be supported by the v2 compiler since v2.0.0\n",
      "  category=FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "from kfp.v2 import compiler  # noqa: F811\n",
    "\n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=pipeline, package_path=\"tensorboard-pipeline-integration.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ApRbxsjF0Qi-"
   },
   "source": [
    "## Run the pipeline\n",
    "\n",
    "Next, run the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "g9mnleE20RlN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/998979163436/locations/us-central1/pipelineJobs/tb-pipeline-integration-20240213050904\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/998979163436/locations/us-central1/pipelineJobs/tb-pipeline-integration-20240213050904')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/tb-pipeline-integration-20240213050904?project=998979163436\n",
      "PipelineJob projects/998979163436/locations/us-central1/pipelineJobs/tb-pipeline-integration-20240213050904 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/998979163436/locations/us-central1/pipelineJobs/tb-pipeline-integration-20240213050904 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/998979163436/locations/us-central1/pipelineJobs/tb-pipeline-integration-20240213050904 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/998979163436/locations/us-central1/pipelineJobs/tb-pipeline-integration-20240213050904 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/998979163436/locations/us-central1/pipelineJobs/tb-pipeline-integration-20240213050904 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/998979163436/locations/us-central1/pipelineJobs/tb-pipeline-integration-20240213050904 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/998979163436/locations/us-central1/pipelineJobs/tb-pipeline-integration-20240213050904 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob run completed. Resource name: projects/998979163436/locations/us-central1/pipelineJobs/tb-pipeline-integration-20240213050904\n"
     ]
    }
   ],
   "source": [
    "DISPLAY_NAME = \"tb-pipeline-integration_\" + UUID\n",
    "\n",
    "job = aiplatform.PipelineJob(\n",
    "    display_name=DISPLAY_NAME,\n",
    "    template_path=\"tensorboard-pipeline-integration.json\",\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    ")\n",
    "\n",
    "job.run()\n",
    "\n",
    "! rm tensorboard-pipeline-integration.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "abBEtkyw4xxq"
   },
   "source": [
    "## Check training logs\n",
    "\n",
    "The Vertex AI TensorBoard web app provides a visualization of logs associated with a Vertex AI TensorBoard experiment. This web application offers several tools and dashboards to visualize and compare data across experiment runs. \n",
    "\n",
    "Learn more see [View Vertex AI TensorBoard data](https://cloud.google.com/vertex-ai/docs/experiments/tensorboard-view).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TFEriiywMZga"
   },
   "source": [
    "## Cleaning up\n",
    "\n",
    "To clean up all Google Cloud resources used in this project, you can [delete the Google Cloud project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) you used for the tutorial.\n",
    "\n",
    "Otherwise, **if you created the individual resources in the notebook** you can delete these resouces as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O1Je2JZTMoMg"
   },
   "outputs": [],
   "source": [
    "# Delete GCS bucket.\n",
    "# ! gsutil -m rm -r {BUCKET_URI}\n",
    "\n",
    "# Delete TensorBoard instance.\n",
    "# ! gcloud ai tensorboards delete {TENSORBOARD_RESOURCE_NAME}\n",
    "\n",
    "# Delete custom job.\n",
    "# job.delete()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "tensorboard_vertex_ai_pipelines_integration.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m95",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m95"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
